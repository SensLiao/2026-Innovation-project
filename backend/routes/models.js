
import express from 'express';
import multer from 'multer';
import sharp from 'sharp';
import * as ort from 'onnxruntime-node';
import fs from 'fs';
import axios from 'axios';

import globals from '../globals.js';

const router = express.Router();

// 2. Variables initialization
const storage = multer.memoryStorage();
const upload = multer({ storage });

// 3. Load Image as tensor
async function loadImageAsTensor(imageBuffer) {
  // Step 1: ä½¿ç”¨ sharp è¯»å– Bufferï¼Œè·å–åŸå§‹åƒç´ æ•°æ®ï¼ˆHWC, Uint8ï¼‰
  const { data, info } = await sharp(imageBuffer).raw().toBuffer({ resolveWithObject: true });

  console.log('Channels:', info.channels);
  const height = info.height;
  const width = info.width;

  // Step 2: è½¬æˆ float32ï¼Œä¿ç•™ [0, 255] å€¼åŸŸ
  const floatData = Float32Array.from(data);

  // Step 3: æ„é€  ONNX è¾“å…¥ Tensor (H, W, 3)
  const tensor = new ort.Tensor('float32', floatData, [height, width, 3]);

  console.log('âœ… æµ‹è¯•å›¾ç‰‡è½¬æ¢ä¸º Tensor æˆåŠŸï¼');
  return tensor;
}

// 4. image encoder running
async function runImageEncoder(imageTensor, encoder) {
  // Step 1: æ‰§è¡Œæ¨ç†
  const feeds = { input_image: imageTensor };
  const results = await encoder.run(feeds);

  // Step 2: è·å–è¾“å‡ºç»“æœ
  const embedding = results.image_embeddings;

  // Step3: æ‰“å°è¾“å‡ºç»“æœ
  console.log('âœ… image encoder æ¨ç†æˆåŠŸï¼');
  console.log('è¾“å‡ºç»´åº¦:', embedding.dims);

  return embedding; // è¿”å›è¾“å‡ºç»“æœ
}

// 5. Image decoder running
async function runImageDecoder(feeds, decoder) {
  const results = await decoder.run(feeds);
  // results : {"masks", "iou_predictions", "low_res_masks"}
  const masks = results.masks;
  const iou_predictions = results.iou_predictions;
  const low_res_masks = results.low_res_masks;
  console.log('âœ… image decoder æ¨ç†æˆåŠŸï¼');

  return { masks, iou_predictions, low_res_masks };
}

// 6. Convert normalArray to float32Array
function convertToTensor(normalArray, dims) {
  const float32Array = new Float32Array(normalArray);
  const tensor = new ort.Tensor('float32', float32Array, dims);
  return tensor;
}

// 7.Image encoder route
router.post('/load_model', upload.single('image'), async (req, res) => {
  try {
    //1. get the image file from the frontend
    const file = req.file;
    if (!file) {
      return res.status(400).json({ error: 'No image file uploaded' });
    } else {
      console.log('âœ… æ”¶åˆ°å›¾ç‰‡:', file.originalname, file.mimetype, file.size);
    }

    //2.load the ONNX image encoder model
    const encoder = globals.onnxModels.encoder;

    //3. convert the image to tensor
    const imageTensor = await loadImageAsTensor(file.buffer);
    console.log('âœ… å›¾ç‰‡è½¬æ¢ä¸º Tensor æˆåŠŸï¼');

    //4. run the image encoder
    const image_embeddings = await runImageEncoder(imageTensor, encoder);
    console.log('âœ… å›¾ç‰‡embedding æˆåŠŸï¼');
    return res.status(200).json({
      message: 'Image embeddings generated successfully',
      image_embeddings: Array.from(image_embeddings.data),
      embedding_dims: image_embeddings.dims
    });
  } catch (error) {
    console.error('âŒ Error loading model:', error);
    return res.status(500).json({ error: 'Failed to output the image embedding' });
  }
});

// 8.Image decoder route
router.post('/run_model', async (req, res) => {
  try {
    let {
      image_embeddings,   // float[] (flatten)
      embedding_dims,     // e.g. [1, 256, 64, 64]
      point_coords,       // e.g. [[x,y], ...] (åƒç´ åæ ‡)
      point_labels,       // e.g. [1, 0, ...]
      mask_input,         // optional: float[] (1*1*lowRes*lowRes)
      has_mask_input,     // optional: [0] or [1]
      orig_im_size        // [H, W]
    } = req.body;

    if (!image_embeddings || !embedding_dims) {
      return res.status(400).json({ error: 'Image embeddings not generated yet' });
    }

    const decoder = globals.onnxModels.decoder;
    if (!decoder) {
      return res.status(500).json({ error: 'Image decoder model not loaded' });
    }

    // ---- helpersï¼ˆåªåœ¨æ­¤è·¯ç”±å†…ç”¨ï¼‰----
    const getTargetLength = (embeddingDims) => {
      // SAM/MedSAMï¼šgrid * 16
      const grid = embeddingDims[2];
      return grid * 16;
    };

    const applyCoordsToTarget = (points, origH, origW, targetLength) => {
      const scale = targetLength / Math.max(origH, origW);
      const newH = Math.round(origH * scale);
      const newW = Math.round(origW * scale);
      return points.map(([x, y]) => [
        x * (newW / origW),
        y * (newH / origH)
      ]);
    };

    const logitsTo01Flat = (arr) => {
      const out = new Uint8Array(arr.length);
      for (let i = 0; i < arr.length; i++) out[i] = arr[i] > 0 ? 1 : 0;
      return out;
    };

    // 0) åŸå›¾å°ºå¯¸
    let [origH, origW] = Array.isArray(orig_im_size) ? orig_im_size : [0, 0];
    origH = Number(origH);
    origW = Number(origW);

    // 1) ç”± embedding_dims æ¨å› targetLength / lowRes
    const targetLength = getTargetLength(embedding_dims); // å¸¸è§ 1024 æˆ– 256
    const lowRes = targetLength / 4;                      // å¸¸è§ 256 æˆ– 64

    console.log('âœ… embedding_dims:', embedding_dims, 'â†’ targetLength:', targetLength, 'lowRes:', lowRes);

    // 2) image_embeddings
    const embTensor = new ort.Tensor('float32', Float32Array.from(image_embeddings), embedding_dims);

    // 3) points + labelsï¼šåæ ‡æ˜ å°„ + padding ç‚¹
    const pts = Array.isArray(point_coords) ? point_coords : [];
    const lbs = Array.isArray(point_labels) ? point_labels : [];

    const mapped = applyCoordsToTarget(pts, origH, origW, targetLength);
    // è¿½åŠ  padding ç‚¹ (0,0), label = -1ï¼ˆæ—  box æ—¶å»ºè®®æ€»è¡¥ï¼‰
    mapped.push([0.0, 0.0]);
    lbs.push(-1);

    const numPts = mapped.length;
    const coordsTensor = new ort.Tensor('float32', Float32Array.from(mapped.flat()), [1, numPts, 2]);
    const labelsTensor = new ort.Tensor('float32', Float32Array.from(lbs), [1, numPts]);

    // 4) mask_input / has_mask_inputï¼šå°ºå¯¸åŠ¨æ€åŒ¹é… lowRes
    const expectedLen = 1 * 1 * lowRes * lowRes;
    let maskTensor, hasMaskTensor;

    if (mask_input && mask_input.length === expectedLen) {
      maskTensor = new ort.Tensor('float32', Float32Array.from(mask_input), [1, 1, lowRes, lowRes]);
      if (has_mask_input && has_mask_input.length === 1) {
        hasMaskTensor = new ort.Tensor('float32', Float32Array.from(has_mask_input), [1]);
      } else {
        const anyNonZero = mask_input.some((v) => v !== 0);
        hasMaskTensor = new ort.Tensor('float32', Float32Array.from([anyNonZero ? 1 : 0]), [1]);
      }
    } else {
      maskTensor = new ort.Tensor('float32', new Float32Array(expectedLen), [1, 1, lowRes, lowRes]); // å…¨é›¶
      hasMaskTensor = new ort.Tensor('float32', Float32Array.from([0]), [1]);
    }

    // 5) orig_im_size
    const sizeTensor = new ort.Tensor('float32', Float32Array.from([origH, origW]), [2]);

    const feeds = {
      image_embeddings: embTensor,
      point_coords: coordsTensor,
      point_labels: labelsTensor,
      mask_input: maskTensor,
      has_mask_input: hasMaskTensor,
      orig_im_size: sizeTensor
    };
    const { masks, iou_predictions, low_res_masks } = await runImageDecoder(feeds, decoder);

    console.log('Mask shape:', masks.dims); // å…¸å‹ [1,1,H,W]
    console.log('Low-res masks shape:', low_res_masks.dims); // å…¸å‹ [1,1,lowRes,lowRes]
    console.log('IOU predictions:', Array.from(iou_predictions.data));

    // 6) ç›´æ¥ logits > 0
    const final_mask = Array.from(logitsTo01Flat(Array.from(masks.data)));

    return res.status(200).json({
      message: 'Image decoder ran successfully',
      masks: final_mask,
      masks_shape: masks.dims,
      iou_predictions: Array.from(iou_predictions.data),
      iou_shape: iou_predictions.dims,
      low_res_masks: Array.from(low_res_masks.data),
      low_res_masks_shape: low_res_masks.dims
    });
  } catch (error) {
    console.error('âŒ Error running model:', error);
    return res.status(500).json({ error: 'Failed to run the image decoder' });
  }
});

// ============================================================
// N8N ROUTES - COMMENTED OUT (replaced by agentRoute.js)
// ============================================================
// 9. Medical Analysis router -- n8n version (deprecated)
// router.post('/medical_report_init', async (req, res) => {
//   try {
//     const { final_image } = req.body;
//     if (!final_image) {
//       return res.status(400).json({ error: 'No final image provided' });
//     }
//     const systemPrompt = `...`;  // truncated for brevity
//     const url = 'http://localhost:5678/webhook-test/15f56758-4d20-48e2-aca8-13188bf401d7';
//     const response = await axios.post(url, message, { timeout: 120000 });
//     return res.status(200).json({ message: 'Medical report generated successfully', report: response.data });
//   } catch (error) {
//     return res.status(500).json({ error: 'Failed to generate the medical report' });
//   }
// });

// 10. Report refinement router -- n8n version (deprecated)
// router.post('/medical_report_rein', async (req, res) => {
//   res.status(501).json({ error: 'This feature is not implemented yet' });
// });
// ============================================================

// 11.Testing functions
async function test(fileBuffer) {
  // --- tiny helpers (only for this test) ---
  const getTargetLength = (embeddingDims) => {
    // embeddingDims å½¢å¦‚ [1, 256, G, G]ï¼ŒG*16 å°±æ˜¯é•¿è¾¹ target_length
    const grid = embeddingDims[2];
    return grid * 16;
  };

  const applyCoordsToTarget = (points, origH, origW, targetLength) => {
    const scale = targetLength / Math.max(origH, origW);
    const newH = Math.round(origH * scale);
    const newW = Math.round(origW * scale);
    return points.map(([x, y]) => [x * (newW / origW), y * (newH / origH)]);
  };

  const logitsTo01Flat = (flat) => {
    const out = new Uint8Array(flat.length);
    for (let i = 0; i < flat.length; i++) out[i] = flat[i] > 0 ? 1 : 0;
    return out;
  };

  const to2D = (flat, h, w) => {
    const rows = [];
    for (let y = 0; y < h; y++) {
      rows.push(Array.from(flat.slice(y * w, (y + 1) * w)));
    }
    return rows;
  };

  // 1) åŸå›¾å°ºå¯¸
  const { width: origW, height: origH } = await sharp(fileBuffer).metadata();

  // 2) ç¼–ç å™¨ï¼šæ³¨æ„ä½ å·²ç”¨ --use-preprocessï¼Œæ‰€ä»¥ç›´æ¥å–‚ HWC/0-255 å³å¯
  const imageTensor = await loadImageAsTensor(fileBuffer);
  const embedding = await runImageEncoder(imageTensor, globals.onnxModels.encoder);

  // 3) ç”± embedding ç»´åº¦æ¨å› target_length & low-res å°ºå¯¸
  const targetLength = (function getTL(dims) {
    // dims e.g. [1, 256, 64, 64] => targetLength = 64 * 16 = 1024
    const grid = dims[2];
    return grid * 16;
  })(embedding.dims);
  const lowRes = targetLength / 4;

  console.log('ğŸ” embedding.dims =', embedding.dims, '=> targetLength =', targetLength, 'lowRes =', lowRes);

  // 4) æ„é€ æç¤ºï¼šå•ç‚¹ + padding ç‚¹
  const rawPoints = [[336, 275]];
  const rawLabels = [1]; // 1=æ­£ç‚¹
  const mapped = applyCoordsToTarget(rawPoints, origH, origW, targetLength);

  // è¿½åŠ  padding ç‚¹ (0,0), label=-1 ä»¥ç¬¦åˆè§£ç å™¨çº¦å®š
  mapped.push([0.0, 0.0]);
  rawLabels.push(-1);

  const numPts = mapped.length;
  const coordsTensor = new ort.Tensor('float32', Float32Array.from(mapped.flat()), [1, numPts, 2]);
  const labelsTensor = new ort.Tensor('float32', Float32Array.from(rawLabels), [1, numPts]);

  // 5) å‡†å¤‡ mask_inputï¼ˆå…¨é›¶ï¼‰ã€has_mask_inputï¼ˆ0ï¼‰
  const mask_input = new ort.Tensor('float32', new Float32Array(1 * 1 * lowRes * lowRes), [1, 1, lowRes, lowRes]);
  const has_mask_input = new ort.Tensor('float32', Float32Array.from([0]), [1]);

  // 6) orig_im_size
  const orig_im_size = new ort.Tensor('float32', Float32Array.from([origH, origW]), [2]);

  // 7) è§£ç å™¨
  const decoder = globals.onnxModels.decoder;
  const feeds = {
    image_embeddings: embedding,
    point_coords: coordsTensor,
    point_labels: labelsTensor,
    mask_input: mask_input,
    has_mask_input: has_mask_input,
    orig_im_size: orig_im_size
  };

  const { masks, iou_predictions, low_res_masks } = await runImageDecoder(feeds, decoder);

  console.log('âœ… decoder done. masks shape:', masks.dims, 'low_res_masks shape:', low_res_masks.dims);
  console.log('IOU predictions:', Array.from(iou_predictions.data));

  // 8) logits ç›´æ¥ > 0 å¾—åˆ° 0/1
  const masksFlat01 = logitsTo01Flat(Array.from(masks.data));

  // 9) ç”¨çœŸå®ç»´åº¦å†™å…¥è°ƒè¯•æ–‡ä»¶ï¼ˆä¸è¦ç¡¬ç¼–ç  512x512ï¼‰
  const H = masks.dims[2],
    W = masks.dims[3];
  const masks2D = to2D(masksFlat01, H, W);
  fs.writeFileSync('mask.txt', masks2D.map((row) => row.join(' ')).join('\n'));

  console.log('ğŸ“ mask written to mask.txt with shape', H, 'x', W);
}

// ESM å¯¼å‡ºï¼ˆå‘½åå¯¼å‡ºï¼‰
export { router, test };
