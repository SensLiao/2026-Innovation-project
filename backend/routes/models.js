
import express from 'express';
import multer from 'multer';
import sharp from 'sharp';
import * as ort from 'onnxruntime-node';
import fs from 'fs';
import axios from 'axios';

import globals from '../globals.js';

const router = express.Router();

// 2. Variables initialization
const storage = multer.memoryStorage();
const upload = multer({ storage });

// 3. Load Image as tensor
async function loadImageAsTensor(imageBuffer) {
  // Step 1: ä½¿ç”¨ sharp è¯»å– Bufferï¼Œè·å–åŸå§‹åƒç´ æ•°æ®ï¼ˆHWC, Uint8ï¼‰
  const { data, info } = await sharp(imageBuffer).raw().toBuffer({ resolveWithObject: true });

  console.log('Channels:', info.channels);
  const height = info.height;
  const width = info.width;

  // Step 2: è½¬æˆ float32ï¼Œä¿ç•™ [0, 255] å€¼åŸŸ
  const floatData = Float32Array.from(data);

  // Step 3: æ„é€  ONNX è¾“å…¥ Tensor (H, W, 3)
  const tensor = new ort.Tensor('float32', floatData, [height, width, 3]);

  console.log('âœ… æµ‹è¯•å›¾ç‰‡è½¬æ¢ä¸º Tensor æˆåŠŸï¼');
  return tensor;
}

// 4. image encoder running
async function runImageEncoder(imageTensor, encoder) {
  // Step 1: æ‰§è¡Œæ¨ç†
  const feeds = { input_image: imageTensor };
  const results = await encoder.run(feeds);

  // Step 2: è·å–è¾“å‡ºç»“æœ
  const embedding = results.image_embeddings;

  // Step3: æ‰“å°è¾“å‡ºç»“æœ
  console.log('âœ… image encoder æ¨ç†æˆåŠŸï¼');
  console.log('è¾“å‡ºç»´åº¦:', embedding.dims);

  return embedding; // è¿”å›è¾“å‡ºç»“æœ
}

// 5. Image decoder running
async function runImageDecoder(feeds, decoder) {
  const results = await decoder.run(feeds);
  // results : {"masks", "iou_predictions", "low_res_masks"}
  const masks = results.masks;
  const iou_predictions = results.iou_predictions;
  const low_res_masks = results.low_res_masks;
  console.log('âœ… image decoder æ¨ç†æˆåŠŸï¼');

  return { masks, iou_predictions, low_res_masks };
}

// 6. Convert normalArray to float32Array
function convertToTensor(normalArray, dims) {
  const float32Array = new Float32Array(normalArray);
  const tensor = new ort.Tensor('float32', float32Array, dims);
  return tensor;
}

// 7.Image encoder route
router.post('/load_model', upload.single('image'), async (req, res) => {
  try {
    //1. get the image file from the frontend
    const file = req.file;
    if (!file) {
      return res.status(400).json({ error: 'No image file uploaded' });
    } else {
      console.log('âœ… æ”¶åˆ°å›¾ç‰‡:', file.originalname, file.mimetype, file.size);
    }

    //2.load the ONNX image encoder model
    const encoder = globals.onnxModels.encoder;

    //3. convert the image to tensor
    const imageTensor = await loadImageAsTensor(file.buffer);
    console.log('âœ… å›¾ç‰‡è½¬æ¢ä¸º Tensor æˆåŠŸï¼');

    //4. run the image encoder
    const image_embeddings = await runImageEncoder(imageTensor, encoder);
    console.log('âœ… å›¾ç‰‡embedding æˆåŠŸï¼');
    return res.status(200).json({
      message: 'Image embeddings generated successfully',
      image_embeddings: Array.from(image_embeddings.data),
      embedding_dims: image_embeddings.dims
    });
  } catch (error) {
    console.error('âŒ Error loading model:', error);
    return res.status(500).json({ error: 'Failed to output the image embedding' });
  }
});

// 8.Image decoder route
router.post('/run_model', async (req, res) => {
  try {
    let {
      image_embeddings,   // float[] (flatten)
      embedding_dims,     // e.g. [1, 256, 64, 64]
      point_coords,       // e.g. [[x,y], ...] (åƒç´ åæ ‡)
      point_labels,       // e.g. [1, 0, ...]
      boxes,              // e.g. [[x0,y0,x1,y1], ...] â­ æ–°å¢
      mask_input,         // optional: float[] (1*1*lowRes*lowRes)
      has_mask_input,     // optional: [0] or [1]
      orig_im_size        // [H, W]
    } = req.body;

    if (!image_embeddings || !embedding_dims) {
      return res.status(400).json({ error: 'Image embeddings not generated yet' });
    }

    const decoder = globals.onnxModels.decoder;
    if (!decoder) {
      return res.status(500).json({ error: 'Image decoder model not loaded' });
    }

    // ---- helpersï¼ˆåªåœ¨æ­¤è·¯ç”±å†…ç”¨ï¼‰----
    const getTargetLength = (embeddingDims) => {
      // SAM/MedSAMï¼šgrid * 16
      const grid = embeddingDims[2];
      return grid * 16;
    };

    const applyCoordsToTarget = (points, origH, origW, targetLength) => {
      const scale = targetLength / Math.max(origH, origW);
      const newH = Math.round(origH * scale);
      const newW = Math.round(origW * scale);
      return points.map(([x, y]) => [
        x * (newW / origW),
        y * (newH / origH)
      ]);
    };

    const logitsTo01Flat = (arr) => {
      const out = new Uint8Array(arr.length);
      for (let i = 0; i < arr.length; i++) out[i] = arr[i] > 0 ? 1 : 0;
      return out;
    };

    // 0) åŸå›¾å°ºå¯¸
    let [origH, origW] = Array.isArray(orig_im_size) ? orig_im_size : [0, 0];
    origH = Number(origH);
    origW = Number(origW);

    // 1) ç”± embedding_dims æ¨å› targetLength / lowRes
    const targetLength = getTargetLength(embedding_dims); // å¸¸è§ 1024 æˆ– 256
    const lowRes = targetLength / 4;                      // å¸¸è§ 256 æˆ– 64

    console.log('âœ… embedding_dims:', embedding_dims, 'â†’ targetLength:', targetLength, 'lowRes:', lowRes);

    // 2) image_embeddings
    const embTensor = new ort.Tensor('float32', Float32Array.from(image_embeddings), embedding_dims);

    // 3) points + labelsï¼šåæ ‡æ˜ å°„ + padding ç‚¹
    const pts = Array.isArray(point_coords) ? point_coords : [];
    const lbs = Array.isArray(point_labels) ? point_labels : [];

    const mapped = applyCoordsToTarget(pts, origH, origW, targetLength);
    // è¿½åŠ  padding ç‚¹ (0,0), label = -1ï¼ˆæ—  box æ—¶å»ºè®®æ€»è¡¥ï¼‰
    mapped.push([0.0, 0.0]);
    lbs.push(-1);

    const numPts = mapped.length;
    const coordsTensor = new ort.Tensor('float32', Float32Array.from(mapped.flat()), [1, numPts, 2]);
    const labelsTensor = new ort.Tensor('float32', Float32Array.from(lbs), [1, numPts]);

    // 4) mask_input / has_mask_inputï¼šå°ºå¯¸åŠ¨æ€åŒ¹é… lowRes
    const expectedLen = 1 * 1 * lowRes * lowRes;
    let maskTensor, hasMaskTensor;

    if (mask_input && mask_input.length === expectedLen) {
      maskTensor = new ort.Tensor('float32', Float32Array.from(mask_input), [1, 1, lowRes, lowRes]);
      if (has_mask_input && has_mask_input.length === 1) {
        hasMaskTensor = new ort.Tensor('float32', Float32Array.from(has_mask_input), [1]);
      } else {
        const anyNonZero = mask_input.some((v) => v !== 0);
        hasMaskTensor = new ort.Tensor('float32', Float32Array.from([anyNonZero ? 1 : 0]), [1]);
      }
    } else {
      maskTensor = new ort.Tensor('float32', new Float32Array(expectedLen), [1, 1, lowRes, lowRes]); // å…¨é›¶
      hasMaskTensor = new ort.Tensor('float32', Float32Array.from([0]), [1]);
    }

    // 5) boxes: å¤„ç†æ¡†æç¤º
    const boxesArray = Array.isArray(boxes) ? boxes : [];
    let boxesTensor;
    if (boxesArray.length > 0) {
      // æ˜ å°„ box åæ ‡åˆ° target length
      const mappedBoxes = boxesArray.map(([x0, y0, x1, y1]) => {
        const scale = targetLength / Math.max(origH, origW);
        const newH = Math.round(origH * scale);
        const newW = Math.round(origW * scale);
        return [
          x0 * (newW / origW),
          y0 * (newH / origH),
          x1 * (newW / origW),
          y1 * (newH / origH)
        ];
      });
      boxesTensor = new ort.Tensor('float32', Float32Array.from(mappedBoxes.flat()), [1, mappedBoxes.length, 4]);
    } else {
      // ç©º boxes tensor: [1, 0, 4]
      boxesTensor = new ort.Tensor('float32', new Float32Array(0), [1, 0, 4]);
    }

    // 6) orig_im_size
    const sizeTensor = new ort.Tensor('float32', Float32Array.from([origH, origW]), [2]);

    const feeds = {
      image_embeddings: embTensor,
      point_coords: coordsTensor,
      point_labels: labelsTensor,
      boxes: boxesTensor,
      mask_input: maskTensor,
      has_mask_input: hasMaskTensor,
      orig_im_size: sizeTensor
    };
    const { masks, iou_predictions, low_res_masks } = await runImageDecoder(feeds, decoder);

    console.log('Mask shape:', masks.dims); // å…¸å‹ [1,1,H,W]
    console.log('Low-res masks shape:', low_res_masks.dims); // å…¸å‹ [1,1,lowRes,lowRes]
    console.log('IOU predictions:', Array.from(iou_predictions.data));

    // 7) ç›´æ¥ logits > 0
    const final_mask = Array.from(logitsTo01Flat(Array.from(masks.data)));

    return res.status(200).json({
      message: 'Image decoder ran successfully',
      masks: final_mask,
      masks_shape: masks.dims,
      iou_predictions: Array.from(iou_predictions.data),
      iou_shape: iou_predictions.dims,
      low_res_masks: Array.from(low_res_masks.data),
      low_res_masks_shape: low_res_masks.dims
    });
  } catch (error) {
    console.error('âŒ Error running model:', error);
    return res.status(500).json({ error: 'Failed to run the image decoder' });
  }
});

// ============================================================
// N8N ROUTES - COMMENTED OUT (replaced by agentRoute.js)
// ============================================================
// 9. Medical Analysis router -- n8n version (deprecated)
// router.post('/medical_report_init', async (req, res) => {
//   try {
//     const { final_image } = req.body;
//     if (!final_image) {
//       return res.status(400).json({ error: 'No final image provided' });
//     }
//     const systemPrompt = `...`;  // truncated for brevity
//     const url = 'http://localhost:5678/webhook-test/15f56758-4d20-48e2-aca8-13188bf401d7';
//     const response = await axios.post(url, message, { timeout: 120000 });
//     return res.status(200).json({ message: 'Medical report generated successfully', report: response.data });
//   } catch (error) {
//     return res.status(500).json({ error: 'Failed to generate the medical report' });
//   }
// });

// 10. Report refinement router -- n8n version (deprecated)
// router.post('/medical_report_rein', async (req, res) => {
//   res.status(501).json({ error: 'This feature is not implemented yet' });
// });
// ============================================================

// 11.Testing functions - æµ‹è¯• Point, Box, Mixed ä¸‰ç§æ¨¡å¼
async function test(fileBuffer) {
  // --- tiny helpers (only for this test) ---
  const getTargetLength = (embeddingDims) => {
    const grid = embeddingDims[2];
    return grid * 16;
  };

  const applyCoordsToTarget = (points, origH, origW, targetLength) => {
    const scale = targetLength / Math.max(origH, origW);
    const newH = Math.round(origH * scale);
    const newW = Math.round(origW * scale);
    return points.map(([x, y]) => [x * (newW / origW), y * (newH / origH)]);
  };

  const applyBoxToTarget = (box, origH, origW, targetLength) => {
    const scale = targetLength / Math.max(origH, origW);
    const newH = Math.round(origH * scale);
    const newW = Math.round(origW * scale);
    return [
      box[0] * (newW / origW),
      box[1] * (newH / origH),
      box[2] * (newW / origW),
      box[3] * (newH / origH)
    ];
  };

  const logitsTo01Flat = (flat) => {
    const out = new Uint8Array(flat.length);
    for (let i = 0; i < flat.length; i++) out[i] = flat[i] > 0 ? 1 : 0;
    return out;
  };

  const to2D = (flat, h, w) => {
    const rows = [];
    for (let y = 0; y < h; y++) {
      rows.push(Array.from(flat.slice(y * w, (y + 1) * w)));
    }
    return rows;
  };

  const decoder = globals.onnxModels.decoder;

  // ========== 1) è·å–åŸå›¾å°ºå¯¸ & ç¼–ç  (åªåšä¸€æ¬¡) ==========
  const { width: origW, height: origH } = await sharp(fileBuffer).metadata();
  console.log('ğŸ“ Original image size:', origW, 'x', origH);

  const imageTensor = await loadImageAsTensor(fileBuffer);
  const embedding = await runImageEncoder(imageTensor, globals.onnxModels.encoder);

  const targetLength = getTargetLength(embedding.dims);
  const lowRes = targetLength / 4;
  console.log('ğŸ” embedding.dims =', embedding.dims, '=> targetLength =', targetLength, 'lowRes =', lowRes);

  // å…¬å…±å‚æ•°
  const orig_im_size = new ort.Tensor('float32', Float32Array.from([origH, origW]), [2]);
  const mask_input = new ort.Tensor('float32', new Float32Array(1 * 1 * lowRes * lowRes), [1, 1, lowRes, lowRes]);
  const has_mask_input = new ort.Tensor('float32', Float32Array.from([0]), [1]);

  // ========== TEST 1: Point-only ==========
  console.log('\n' + '='.repeat(50));
  console.log('ğŸ§ª TEST 1: Point-only Segmentation');
  console.log('='.repeat(50));
  {
    const rawPoints = [[336, 275]];
    const rawLabels = [1]; // å‰æ™¯ç‚¹
    const mapped = applyCoordsToTarget(rawPoints, origH, origW, targetLength);
    
    // è¿½åŠ  padding ç‚¹
    mapped.push([0.0, 0.0]);
    rawLabels.push(-1);

    const coordsTensor = new ort.Tensor('float32', Float32Array.from(mapped.flat()), [1, mapped.length, 2]);
    const labelsTensor = new ort.Tensor('float32', Float32Array.from(rawLabels), [1, rawLabels.length]);
    const boxesTensor = new ort.Tensor('float32', new Float32Array(0), [1, 0, 4]); // ç©º boxes

    const feeds = {
      image_embeddings: embedding,
      point_coords: coordsTensor,
      point_labels: labelsTensor,
      boxes: boxesTensor,
      mask_input: mask_input,
      has_mask_input: has_mask_input,
      orig_im_size: orig_im_size
    };

    const { masks, iou_predictions } = await runImageDecoder(feeds, decoder);
    console.log('âœ… Point-only done. Mask shape:', masks.dims, 'IoU:', iou_predictions.data[0].toFixed(4));

    const masksFlat01 = logitsTo01Flat(Array.from(masks.data));
    const H = masks.dims[2], W = masks.dims[3];
    const masks2D = to2D(masksFlat01, H, W);
    fs.writeFileSync('mask_point.txt', masks2D.map((row) => row.join(' ')).join('\n'));
    console.log('ğŸ“ Saved to mask_point.txt');
  }

  // ========== TEST 2: Box-only ==========
  console.log('\n' + '='.repeat(50));
  console.log('ğŸ§ª TEST 2: Box-only Segmentation');
  console.log('='.repeat(50));
  {
    // Box: [x0, y0, x1, y1] - å‡è®¾æ¡†ä½ç›®æ ‡åŒºåŸŸ
    const rawBox = [250, 180, 420, 370]; // æ ¹æ®å›¾åƒè°ƒæ•´
    const mappedBox = applyBoxToTarget(rawBox, origH, origW, targetLength);

    // ç©º points (éœ€è¦æ­£ç¡®çš„å½¢çŠ¶)
    const coordsTensor = new ort.Tensor('float32', new Float32Array(0), [1, 0, 2]);
    const labelsTensor = new ort.Tensor('float32', new Float32Array(0), [1, 0]);
    const boxesTensor = new ort.Tensor('float32', Float32Array.from(mappedBox), [1, 1, 4]);

    const feeds = {
      image_embeddings: embedding,
      point_coords: coordsTensor,
      point_labels: labelsTensor,
      boxes: boxesTensor,
      mask_input: mask_input,
      has_mask_input: has_mask_input,
      orig_im_size: orig_im_size
    };

    const { masks, iou_predictions } = await runImageDecoder(feeds, decoder);
    console.log('âœ… Box-only done. Mask shape:', masks.dims, 'IoU:', iou_predictions.data[0].toFixed(4));

    const masksFlat01 = logitsTo01Flat(Array.from(masks.data));
    const H = masks.dims[2], W = masks.dims[3];
    const masks2D = to2D(masksFlat01, H, W);
    fs.writeFileSync('mask_box.txt', masks2D.map((row) => row.join(' ')).join('\n'));
    console.log('ğŸ“ Saved to mask_box.txt');
  }

  // ========== TEST 3: Mixed (Point + Box) ==========
  console.log('\n' + '='.repeat(50));
  console.log('ğŸ§ª TEST 3: Mixed (Point + Box) Segmentation');
  console.log('='.repeat(50));
  {
    // Box
    const rawBox = [250, 180, 420, 370];
    const mappedBox = applyBoxToTarget(rawBox, origH, origW, targetLength);
    
    // Points: ä¸€ä¸ªå‰æ™¯ç‚¹ + ä¸€ä¸ªèƒŒæ™¯ç‚¹
    const rawPoints = [[336, 275], [200, 100]];
    const rawLabels = [1, 0]; // 1=å‰æ™¯, 0=èƒŒæ™¯
    const mapped = applyCoordsToTarget(rawPoints, origH, origW, targetLength);
    
    // è¿½åŠ  padding ç‚¹
    mapped.push([0.0, 0.0]);
    rawLabels.push(-1);

    const coordsTensor = new ort.Tensor('float32', Float32Array.from(mapped.flat()), [1, mapped.length, 2]);
    const labelsTensor = new ort.Tensor('float32', Float32Array.from(rawLabels), [1, rawLabels.length]);
    const boxesTensor = new ort.Tensor('float32', Float32Array.from(mappedBox), [1, 1, 4]);

    const feeds = {
      image_embeddings: embedding,
      point_coords: coordsTensor,
      point_labels: labelsTensor,
      boxes: boxesTensor,
      mask_input: mask_input,
      has_mask_input: has_mask_input,
      orig_im_size: orig_im_size
    };

    const { masks, iou_predictions } = await runImageDecoder(feeds, decoder);
    console.log('âœ… Mixed done. Mask shape:', masks.dims, 'IoU:', iou_predictions.data[0].toFixed(4));

    const masksFlat01 = logitsTo01Flat(Array.from(masks.data));
    const H = masks.dims[2], W = masks.dims[3];
    const masks2D = to2D(masksFlat01, H, W);
    fs.writeFileSync('mask_mixed.txt', masks2D.map((row) => row.join(' ')).join('\n'));
    console.log('ğŸ“ Saved to mask_mixed.txt');
  }

  console.log('\n' + '='.repeat(50));
  console.log('âœ… All 3 tests completed!');
  console.log('='.repeat(50));
}

// ESM å¯¼å‡ºï¼ˆå‘½åå¯¼å‡ºï¼‰
export { router, test };
